{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aajohn</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abashed</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abigail</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>abjection</th>\n",
       "      <th>able</th>\n",
       "      <th>...</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zorina</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwingli</th>\n",
       "      <th>zwirner</th>\n",
       "      <th>zwirnersssscornelia</th>\n",
       "      <th>élan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cindy Sherman</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerhard Richter</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridget Riley</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 9792 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 aajohn  abandon  abashed  abbot  abhor  abigail  ability  \\\n",
       "Cindy Sherman         0        5        0      0      5       14        0   \n",
       "Gerhard Richter       1       16        0     16      0        0        0   \n",
       "Bridget Riley         0       21       12      0      0        0        5   \n",
       "\n",
       "                 abject  abjection  able  ...   zimmer  zip  zoe  zombies  \\\n",
       "Cindy Sherman        39          5    40  ...        0    5   19       10   \n",
       "Gerhard Richter       0          0    20  ...        0    0    0        0   \n",
       "Bridget Riley         0          0    60  ...       10    0    0        0   \n",
       "\n",
       "                 zorina  zurich  zwingli  zwirner  zwirnersssscornelia  élan  \n",
       "Cindy Sherman        18       0        0        0                    0     0  \n",
       "Gerhard Richter       0     155       64        0                    0    16  \n",
       "Bridget Riley         0       0        0       60                    1     0  \n",
       "\n",
       "[3 rows x 9792 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the document-term matrix\n",
    "import pandas as pd\n",
    "import pickle \n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "#data = data.transpose()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary modules for LDA with gensim\n",
    "# Terminal / Anaconda Navigator: conda install -c conda-forge gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cindy Sherman</th>\n",
       "      <th>Gerhard Richter</th>\n",
       "      <th>Bridget Riley</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aajohn</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abashed</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbot</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abhor</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Cindy Sherman  Gerhard Richter  Bridget Riley\n",
       "aajohn               0                1              0\n",
       "abandon              5               16             21\n",
       "abashed              0                0             12\n",
       "abbot                0               16              0\n",
       "abhor                5                0              0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One of the required inputs is a term-document matrix\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We're going to put the term-document matrix into a new gensim format, from df --> sparse matrix --> gensim corpus\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gensim also requires dictionary of the all terms and their respective location in the term-document matrix\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 2, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"work\" + 0.015*\"art\" + 0.012*\"painting\" + 0.009*\"make\" + 0.008*\"artist\" + 0.008*\"just\" + 0.007*\"gallery\" + 0.007*\"think\" + 0.007*\"look\" + 0.006*\"colour\"'),\n",
       " (1,\n",
       "  '0.016*\"art\" + 0.009*\"work\" + 0.008*\"artist\" + 0.007*\"painting\" + 0.006*\"museum\" + 0.005*\"make\" + 0.004*\"photograph\" + 0.004*\"photo\" + 0.004*\"image\" + 0.003*\"glass\"')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term),\n",
    "# we need to specify two other parameters as well - the number of topics and the number of passes\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.015*\"work\" + 0.015*\"art\" + 0.013*\"painting\" + 0.009*\"make\" + 0.008*\"artist\" + 0.008*\"just\" + 0.007*\"gallery\" + 0.007*\"think\" + 0.007*\"look\" + 0.006*\"colour\"'),\n",
       " (1,\n",
       "  '0.016*\"art\" + 0.010*\"painting\" + 0.008*\"work\" + 0.008*\"artist\" + 0.005*\"glass\" + 0.005*\"window\" + 0.005*\"make\" + 0.004*\"museum\" + 0.004*\"polke\" + 0.004*\"paint\"'),\n",
       " (2,\n",
       "  '0.017*\"art\" + 0.011*\"museum\" + 0.010*\"work\" + 0.010*\"artist\" + 0.010*\"photo\" + 0.007*\"vuitton\" + 0.007*\"present\" + 0.007*\"louis\" + 0.007*\"film\" + 0.007*\"studio\"')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topic=3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.017*\"art\" + 0.011*\"museum\" + 0.010*\"artist\" + 0.010*\"work\" + 0.010*\"photo\" + 0.007*\"vuitton\" + 0.007*\"present\" + 0.007*\"louis\" + 0.007*\"film\" + 0.007*\"studio\"'),\n",
       " (1,\n",
       "  '0.010*\"work\" + 0.008*\"art\" + 0.007*\"artist\" + 0.005*\"make\" + 0.004*\"gallery\" + 0.004*\"just\" + 0.004*\"painting\" + 0.004*\"look\" + 0.003*\"photograph\" + 0.003*\"think\"'),\n",
       " (2,\n",
       "  '0.016*\"art\" + 0.010*\"painting\" + 0.008*\"work\" + 0.008*\"artist\" + 0.005*\"glass\" + 0.005*\"window\" + 0.005*\"make\" + 0.004*\"museum\" + 0.004*\"polke\" + 0.004*\"paint\"'),\n",
       " (3,\n",
       "  '0.016*\"work\" + 0.015*\"art\" + 0.013*\"painting\" + 0.009*\"make\" + 0.008*\"artist\" + 0.008*\"just\" + 0.007*\"gallery\" + 0.007*\"think\" + 0.007*\"look\" + 0.006*\"colour\"')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA for num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling - Attempt #2 (Nouns Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>artist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cindy Sherman</th>\n",
       "      <td>-PRON- actually hate the idea of selfie say ci...</td>\n",
       "      <td>Cindy Sherman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerhard Richter</th>\n",
       "      <td>the exhibition at de pont museum in tilburg ne...</td>\n",
       "      <td>Gerhard Richter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridget Riley</th>\n",
       "      <td>to walk into bridget riley exhibition of new w...</td>\n",
       "      <td>Bridget Riley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        transcript  \\\n",
       "Cindy Sherman    -PRON- actually hate the idea of selfie say ci...   \n",
       "Gerhard Richter  the exhibition at de pont museum in tilburg ne...   \n",
       "Bridget Riley    to walk into bridget riley exhibition of new w...   \n",
       "\n",
       "                       artist_id  \n",
       "Cindy Sherman      Cindy Sherman  \n",
       "Gerhard Richter  Gerhard Richter  \n",
       "Bridget Riley      Bridget Riley  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data, before the CountVectorizer step\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cindy Sherman</th>\n",
       "      <td>idea sherman image iphone oh queen voice kind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerhard Richter</th>\n",
       "      <td>exhibition museum tilburg netherland june osca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridget Riley</th>\n",
       "      <td>bridget exhibition work everything couple exce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        transcript\n",
       "Cindy Sherman    idea sherman image iphone oh queen voice kind ...\n",
       "Gerhard Richter  exhibition museum tilburg netherland june osca...\n",
       "Bridget Riley    bridget exhibition work everything couple exce..."
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abigail</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>abjection</th>\n",
       "      <th>abraham</th>\n",
       "      <th>abramovic</th>\n",
       "      <th>abrasion</th>\n",
       "      <th>...</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwingli</th>\n",
       "      <th>zwirner</th>\n",
       "      <th>zwirnersssscornelia</th>\n",
       "      <th>élan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cindy Sherman</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerhard Richter</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridget Riley</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5955 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 abandon  abbot  abhor  abigail  ability  abject  abjection  \\\n",
       "Cindy Sherman          5      0      5        9        0       1          5   \n",
       "Gerhard Richter        0     16      0        0        0       0          0   \n",
       "Bridget Riley          5      0      0        0        5       0          0   \n",
       "\n",
       "                 abraham  abramovic  abrasion  ...   zhang  zigzag  zillion  \\\n",
       "Cindy Sherman          0          6         0  ...       0       0        0   \n",
       "Gerhard Richter       16          0        16  ...       5       0        5   \n",
       "Bridget Riley          0          0         0  ...       0      10        0   \n",
       "\n",
       "                 zimmer  zoe  zurich  zwingli  zwirner  zwirnersssscornelia  \\\n",
       "Cindy Sherman         0   19       0        0        0                    0   \n",
       "Gerhard Richter       0    0      21       48        0                    0   \n",
       "Bridget Riley        10    0       0        0       52                    1   \n",
       "\n",
       "                 élan  \n",
       "Cindy Sherman       0  \n",
       "Gerhard Richter    16  \n",
       "Bridget Riley       0  \n",
       "\n",
       "[3 rows x 5955 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Re-add the additional stop words since we are recreating the document-term matrix\n",
    "add_stop_words = ['PRON',\n",
    " 'pron',\n",
    " 'say',\n",
    " 'like',\n",
    " 'cindy',\n",
    " 'sherman',\n",
    " 'gerhard',\n",
    " 'richter',\n",
    " 'bridget',\n",
    " 'riley',\n",
    " 'new',\n",
    " 'york',\n",
    " 'twitter',\n",
    " 'facebook',\n",
    " 'pinterest',\n",
    " 'annual','oh','way','thing','year','ahg','dh','untitled','artist','art','gallery','exhibition','work','museum','party'\n",
    "                 ]\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recreate a document-term matrix with only nouns\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"painting\" + 0.009*\"photo\" + 0.008*\"studio\" + 0.007*\"film\" + 0.007*\"time\" + 0.007*\"photograph\" + 0.006*\"vuitton\" + 0.006*\"series\" + 0.006*\"world\" + 0.005*\"image\"'),\n",
       " (1,\n",
       "  '0.010*\"painting\" + 0.009*\"glass\" + 0.008*\"window\" + 0.006*\"world\" + 0.006*\"image\" + 0.006*\"polke\" + 0.006*\"photograph\" + 0.005*\"paint\" + 0.005*\"painter\" + 0.005*\"time\"')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=2, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"painting\" + 0.009*\"photo\" + 0.008*\"studio\" + 0.007*\"film\" + 0.007*\"time\" + 0.007*\"photograph\" + 0.006*\"vuitton\" + 0.006*\"series\" + 0.006*\"world\" + 0.005*\"image\"'),\n",
       " (1,\n",
       "  '0.010*\"painting\" + 0.009*\"glass\" + 0.008*\"window\" + 0.006*\"world\" + 0.006*\"image\" + 0.006*\"polke\" + 0.006*\"photograph\" + 0.005*\"paint\" + 0.005*\"painter\" + 0.005*\"time\"'),\n",
       " (2,\n",
       "  '0.005*\"painting\" + 0.003*\"world\" + 0.003*\"photograph\" + 0.003*\"window\" + 0.002*\"image\" + 0.002*\"glass\" + 0.002*\"photo\" + 0.002*\"time\" + 0.002*\"painter\" + 0.002*\"paint\"')]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try topics = 3\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=3, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"painting\" + 0.009*\"glass\" + 0.008*\"window\" + 0.007*\"world\" + 0.006*\"image\" + 0.006*\"polke\" + 0.006*\"photograph\" + 0.005*\"paint\" + 0.005*\"painter\" + 0.005*\"time\"'),\n",
       " (1,\n",
       "  '0.017*\"painting\" + 0.008*\"colour\" + 0.008*\"kind\" + 0.008*\"time\" + 0.008*\"world\" + 0.007*\"space\" + 0.007*\"eye\" + 0.006*\"piece\" + 0.006*\"look\" + 0.006*\"use\"'),\n",
       " (2,\n",
       "  '0.018*\"photo\" + 0.013*\"vuitton\" + 0.013*\"film\" + 0.013*\"studio\" + 0.011*\"whitney\" + 0.011*\"gala\" + 0.009*\"series\" + 0.009*\"photograph\" + 0.009*\"woman\" + 0.008*\"image\"'),\n",
       " (3,\n",
       "  '0.003*\"painting\" + 0.002*\"world\" + 0.002*\"photograph\" + 0.002*\"time\" + 0.001*\"image\" + 0.001*\"paint\" + 0.001*\"glass\" + 0.001*\"studio\" + 0.001*\"look\" + 0.001*\"use\"')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Cindy Sherman'), (0, 'Gerhard Richter'), (1, 'Bridget Riley')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldan[corpusn]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "topic 0:painting,image,glass\n",
    "topic 1:painting,time,space,eye\n",
    "topic 2:photo,woman,whitney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a35b84b00>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {'Cindy Sherman': 2, 'Gerhard Richter': 0,'Bridget Riley': 1}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "#fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True)\n",
    "plt.scatter(names,values)\n",
    "#fig.suptitle('Categorical Plotting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling - Attempt #3 (Nouns and Adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's create a function to pull out nouns from a string of text\n",
    "def nouns_adj(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns and adjectives.'''\n",
    "    is_noun_adj = lambda pos: pos == 'NN' or pos == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cindy Sherman</th>\n",
       "      <td>idea cindy sherman discuss recent image iphone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerhard Richter</th>\n",
       "      <td>exhibition museum tilburg netherland june osca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridget Riley</th>\n",
       "      <td>bridget riley exhibition new work everything c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        transcript\n",
       "Cindy Sherman    idea cindy sherman discuss recent image iphone...\n",
       "Gerhard Richter  exhibition museum tilburg netherland june osca...\n",
       "Bridget Riley    bridget riley exhibition new work everything c..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the nouns function to the transcripts to filter only on nouns\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abigail</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>abjection</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>abraham</th>\n",
       "      <th>abramovic</th>\n",
       "      <th>...</th>\n",
       "      <th>zhang</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zimmer</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwingli</th>\n",
       "      <th>zwirner</th>\n",
       "      <th>zwirnersssscornelia</th>\n",
       "      <th>élan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cindy Sherman</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gerhard Richter</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bridget Riley</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7065 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 abandon  abbot  abhor  abigail  ability  abject  abjection  \\\n",
       "Cindy Sherman          5      0      5        9        0      38          5   \n",
       "Gerhard Richter        0     16      0        0        0       0          0   \n",
       "Bridget Riley         10      0      0        0        5       0          0   \n",
       "\n",
       "                 aboriginal  abraham  abramovic  ...   zhang  zigzag  zillion  \\\n",
       "Cindy Sherman             5        0         11  ...       0       0        0   \n",
       "Gerhard Richter           0       16          5  ...       5       0        5   \n",
       "Bridget Riley             0        0          0  ...       0      10        0   \n",
       "\n",
       "                 zimmer  zoe  zurich  zwingli  zwirner  zwirnersssscornelia  \\\n",
       "Cindy Sherman         0   19       0        0        0                    0   \n",
       "Gerhard Richter       0    0      75       48        0                    0   \n",
       "Bridget Riley        10    0       0        0       52                    1   \n",
       "\n",
       "                 élan  \n",
       "Cindy Sherman       0  \n",
       "Gerhard Richter    16  \n",
       "Bridget Riley       0  \n",
       "\n",
       "[3 rows x 7065 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new document-term matrix using only nouns and adjectives, also remove common words with max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the gensim corpus\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Create the vocabulary dictionary\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"polke\" + 0.005*\"cologne\" + 0.005*\"moreread\" + 0.004*\"abstract\" + 0.004*\"stain\" + 0.004*\"cathedral\" + 0.004*\"pärt\" + 0.004*\"germany\" + 0.003*\"arvo\" + 0.003*\"johns\"'),\n",
       " (1,\n",
       "  '0.009*\"vuitton\" + 0.009*\"louis\" + 0.008*\"whitney\" + 0.007*\"gala\" + 0.005*\"metro\" + 0.004*\"abstract\" + 0.003*\"access\" + 0.003*\"stripe\" + 0.003*\"yeah\" + 0.003*\"seurat\"')]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start with 2 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=2, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.018*\"vuitton\" + 0.017*\"louis\" + 0.015*\"whitney\" + 0.015*\"gala\" + 0.011*\"metro\" + 0.006*\"access\" + 0.005*\"sublimation\" + 0.004*\"bag\" + 0.004*\"makeup\" + 0.004*\"monogram\"'),\n",
       " (1,\n",
       "  '0.008*\"polke\" + 0.005*\"cologne\" + 0.005*\"moreread\" + 0.004*\"abstract\" + 0.004*\"stain\" + 0.004*\"cathedral\" + 0.004*\"pärt\" + 0.004*\"germany\" + 0.003*\"arvo\" + 0.003*\"johns\"'),\n",
       " (2,\n",
       "  '0.008*\"abstract\" + 0.005*\"stripe\" + 0.005*\"yeah\" + 0.005*\"seurat\" + 0.005*\"bacon\" + 0.005*\"curve\" + 0.005*\"british\" + 0.004*\"perception\" + 0.004*\"hospital\" + 0.004*\"vertical\"')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 3 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=3, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"vuitton\" + 0.018*\"louis\" + 0.016*\"whitney\" + 0.015*\"gala\" + 0.011*\"metro\" + 0.006*\"access\" + 0.005*\"sublimation\" + 0.005*\"bag\" + 0.005*\"makeup\" + 0.004*\"monogram\"'),\n",
       " (1,\n",
       "  '0.008*\"abstract\" + 0.006*\"stripe\" + 0.006*\"yeah\" + 0.005*\"seurat\" + 0.005*\"bacon\" + 0.005*\"curve\" + 0.005*\"british\" + 0.004*\"perception\" + 0.004*\"hospital\" + 0.004*\"vertical\"'),\n",
       " (2,\n",
       "  '0.001*\"polke\" + 0.001*\"abstract\" + 0.001*\"louis\" + 0.001*\"vuitton\" + 0.000*\"cologne\" + 0.000*\"pärt\" + 0.000*\"cathedral\" + 0.000*\"gala\" + 0.000*\"germany\" + 0.000*\"moreread\"'),\n",
       " (3,\n",
       "  '0.008*\"polke\" + 0.005*\"cologne\" + 0.005*\"moreread\" + 0.004*\"abstract\" + 0.004*\"stain\" + 0.004*\"cathedral\" + 0.004*\"pärt\" + 0.004*\"germany\" + 0.003*\"arvo\" + 0.003*\"johns\"')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try 4 topics\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify Topics in Each Document\n",
    "Out of the 9 topic models we looked at, the nouns and adjectives, 4 topic one made the most sense. So let's pull that down here and run it through some more iterations to get more fine-tuned topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.006*\"polke\" + 0.006*\"abstract\" + 0.003*\"cathedral\" + 0.003*\"cologne\" + 0.003*\"moreread\" + 0.003*\"stain\" + 0.003*\"pärt\" + 0.003*\"british\" + 0.003*\"stripe\" + 0.003*\"germany\"'),\n",
       " (1,\n",
       "  '0.000*\"vuitton\" + 0.000*\"louis\" + 0.000*\"whitney\" + 0.000*\"gala\" + 0.000*\"metro\" + 0.000*\"access\" + 0.000*\"polke\" + 0.000*\"abstract\" + 0.000*\"isbn\" + 0.000*\"bag\"'),\n",
       " (2,\n",
       "  '0.019*\"vuitton\" + 0.018*\"louis\" + 0.016*\"whitney\" + 0.015*\"gala\" + 0.011*\"metro\" + 0.006*\"access\" + 0.005*\"sublimation\" + 0.005*\"bag\" + 0.005*\"makeup\" + 0.004*\"monogram\"'),\n",
       " (3,\n",
       "  '0.000*\"abstract\" + 0.000*\"louis\" + 0.000*\"gala\" + 0.000*\"polke\" + 0.000*\"vuitton\" + 0.000*\"moreread\" + 0.000*\"cologne\" + 0.000*\"cathedral\" + 0.000*\"whitney\" + 0.000*\"metro\"')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our final LDA model (for now)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 'Cindy Sherman'), (0, 'Gerhard Richter'), (0, 'Bridget Riley')]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at which topics each transcript contains\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
